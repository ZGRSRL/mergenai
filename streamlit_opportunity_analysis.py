#!/usr/bin/env python3
"""
Streamlit Ä°lan Analizi YÃ¶netim Paneli
Kritik workflow'u Streamlit Ã¼zerinden yÃ¶netmek iÃ§in
"""

import os
import sys
import streamlit as st
from pathlib import Path
from datetime import datetime
import json
import pandas as pd

# Add current directory to path
sys.path.append('.')

# Page config
st.set_page_config(
    page_title="Ä°lan Analizi - ZGR SAM",
    page_icon="ğŸ“‹",
    layout="wide"
)

# Title
st.title("ğŸ“‹ Ä°lan Analizi YÃ¶netim Paneli")
st.markdown("SAM.gov ilanlarÄ±nÄ± analiz edip RAG sistemine hazÄ±r hale getirin")

# Sidebar
with st.sidebar:
    st.header("âš™ï¸ Ayarlar")
    
    use_llm = st.checkbox("LLM ile Gereksinim Ã‡Ä±karÄ±mÄ±", value=True)
    download_dir = st.text_input("Download Dizini", value="./downloads")
    
    st.markdown("---")
    st.info("""
    **Workflow AdÄ±mlarÄ±:**
    1. Metadata Ã§ekme
    2. DokÃ¼man indirme
    3. Gereksinim Ã§Ä±karÄ±mÄ±
    4. SOW analizi
    5. VeritabanÄ± kaydÄ±
    """)

# Main content
tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ” Ä°lan Analizi",
    "ğŸ“Š Analiz SonuÃ§larÄ±",
    "ğŸ“ DokÃ¼man YÃ¶netimi",
    "ğŸ”— RAG Entegrasyonu"
])

# TAB 1: Ä°lan Analizi
with tab1:
    st.header("Yeni Ä°lan Analizi")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        notice_id = st.text_input(
            "SAM.gov Notice ID",
            value="086008536ec84226ad9de043dc738d06",
            help="Ã–rnek: 086008536ec84226ad9de043dc738d06"
        )
    
    with col2:
        st.markdown("<br>", unsafe_allow_html=True)
        analyze_button = st.button("ğŸš€ Ä°lanÄ± Analiz Et", type="primary", use_container_width=True)
    
    if analyze_button and notice_id:
        with st.spinner("Ä°lan analizi yapÄ±lÄ±yor... Bu iÅŸlem birkaÃ§ dakika sÃ¼rebilir."):
            try:
                from analyze_opportunity_workflow import OpportunityAnalysisWorkflow
                
                # Workflow oluÅŸtur
                workflow = OpportunityAnalysisWorkflow(
                    download_dir=download_dir,
                    use_llm=use_llm
                )
                
                # Progress bar
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Ä°lerleme bilgisi
                status_text.info("Workflow baÅŸlatÄ±lÄ±yor...")
                progress_bar.progress(10)
                
                # Workflow Ã§alÄ±ÅŸtÄ±r
                result = workflow.run(notice_id)
                
                progress_bar.progress(100)
                status_text.empty()
                
                # SonuÃ§larÄ± gÃ¶ster
                if result.success:
                    st.success(f"âœ… Analiz baÅŸarÄ±yla tamamlandÄ±!")
                    
                    # SonuÃ§ Ã¶zeti
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("Metadata", "âœ…" if result.metadata else "âŒ")
                    with col2:
                        st.metric("Dosyalar", len(result.downloaded_files or []))
                    with col3:
                        st.metric("Gereksinimler", "âœ…" if result.extracted_requirements else "âŒ")
                    with col4:
                        st.metric("Analysis ID", result.analysis_id or "N/A")
                    
                    # DetaylÄ± sonuÃ§lar
                    with st.expander("ğŸ“‹ DetaylÄ± SonuÃ§lar", expanded=True):
                        # Metadata
                        if result.metadata:
                            st.subheader("Metadata")
                            st.json(result.metadata)
                        
                        # Gereksinimler
                        if result.extracted_requirements:
                            st.subheader("Ã‡Ä±karÄ±lan Gereksinimler")
                            st.json(result.extracted_requirements)
                        
                        # SOW Analizi
                        if result.sow_analysis:
                            st.subheader("SOW Analizi")
                            st.json(result.sow_analysis)
                        
                        # Ä°ndirilen Dosyalar
                        if result.downloaded_files:
                            st.subheader(f"Ä°ndirilen Dosyalar ({len(result.downloaded_files)})")
                            for i, file_path in enumerate(result.downloaded_files, 1):
                                st.write(f"{i}. {Path(file_path).name}")
                    
                    # Hatalar varsa gÃ¶ster
                    if result.errors:
                        st.warning("âš ï¸ BazÄ± hatalar oluÅŸtu:")
                        for error in result.errors:
                            st.error(error)
                    
                    # SonuÃ§larÄ± session state'e kaydet
                    st.session_state[f'analysis_{notice_id}'] = result
                    
                else:
                    st.error("âŒ Analiz baÅŸarÄ±sÄ±z oldu")
                    if result.errors:
                        for error in result.errors:
                            st.error(error)
                
            except Exception as e:
                st.error(f"Workflow hatasÄ±: {e}")
                import traceback
                st.code(traceback.format_exc())

# TAB 2: Analiz SonuÃ§larÄ±
with tab2:
    st.header("KayÄ±tlÄ± Analiz SonuÃ§larÄ±")
    
    try:
        from sow_analysis_manager import SOWAnalysisManager
        
        sow_manager = SOWAnalysisManager()
        all_sow = sow_manager.get_all_active_sow()
        
        if all_sow:
            st.info(f"ğŸ“Š Toplam {len(all_sow)} aktif analiz bulundu")
            
            # Tablo gÃ¶rÃ¼nÃ¼mÃ¼
            df_data = []
            for sow in all_sow[:20]:  # Ä°lk 20
                sow_payload = sow.get('sow_payload', {}) or {}
                metadata = sow_payload.get('metadata', {}) or {}
                
                df_data.append({
                    'Notice ID': sow.get('notice_id', 'N/A'),
                    'Title': metadata.get('title', 'N/A')[:50],
                    'Agency': metadata.get('agency', 'N/A'),
                    'Created': sow.get('created_at', 'N/A'),
                    'Analysis ID': sow.get('analysis_id', 'N/A')
                })
            
            if df_data:
                df = pd.DataFrame(df_data)
                st.dataframe(df, use_container_width=True)
                
                # Detay gÃ¶rÃ¼ntÃ¼leme
                selected_notice = st.selectbox(
                    "Detay gÃ¶rÃ¼ntÃ¼lemek iÃ§in Notice ID seÃ§in",
                    options=[sow.get('notice_id') for sow in all_sow]
                )
                
                if selected_notice:
                    selected_sow = next((s for s in all_sow if s.get('notice_id') == selected_notice), None)
                    if selected_sow:
                        st.subheader(f"Analiz DetaylarÄ±: {selected_notice}")
                        st.json(selected_sow)
        else:
            st.info("HenÃ¼z analiz yapÄ±lmamÄ±ÅŸ. Ä°lan Analizi sekmesinden yeni analiz baÅŸlatÄ±n.")
    
    except Exception as e:
        st.error(f"VeritabanÄ± baÄŸlantÄ± hatasÄ±: {e}")

# TAB 3: DokÃ¼man YÃ¶netimi
with tab3:
    st.header("Ä°ndirilen DokÃ¼manlar")
    
    downloads_path = Path(download_dir)
    
    if downloads_path.exists():
        # Opportunity klasÃ¶rlerini listele
        opp_dirs = [d for d in downloads_path.iterdir() if d.is_dir()]
        
        if opp_dirs:
            selected_opp = st.selectbox(
                "Opportunity seÃ§in",
                options=[d.name for d in opp_dirs]
            )
            
            if selected_opp:
                opp_dir = downloads_path / selected_opp
                files = list(opp_dir.rglob('*'))
                files = [f for f in files if f.is_file()]
                
                st.info(f"ğŸ“ {selected_opp} iÃ§in {len(files)} dosya bulundu")
                
                for i, file_path in enumerate(files[:10], 1):  # Ä°lk 10
                    col1, col2, col3 = st.columns([3, 1, 1])
                    with col1:
                        st.write(f"ğŸ“„ {file_path.name}")
                    with col2:
                        file_size = file_path.stat().st_size
                        st.write(f"{file_size / 1024:.1f} KB")
                    with col3:
                        if st.button("GÃ¶rÃ¼ntÃ¼le", key=f"view_{i}"):
                            st.info(f"Dosya yolu: {file_path}")
        else:
            st.info("HenÃ¼z dokÃ¼man indirilmemiÅŸ.")
    else:
        st.warning(f"Download dizini bulunamadÄ±: {downloads_path}")

# TAB 4: RAG Entegrasyonu
with tab4:
    st.header("RAG Sistemi Entegrasyonu")
    
    st.markdown("""
    ### ğŸ“š RAG Sistemi Durumu
    
    Ä°lan analizi tamamlandÄ±ktan sonra:
    1. **Semantic Search:** 172,402 chunk'tan benzer fÄ±rsatlarÄ± bul
    2. **Best Practices:** GeÃ§miÅŸ tekliflerden Ã¶ÄŸren
    3. **Teklif TaslaÄŸÄ±:** Analiz + RAG ile teklif oluÅŸtur
    """)
    
    notice_id_rag = st.text_input(
        "RAG Analizi iÃ§in Notice ID",
        value="086008536ec84226ad9de043dc738d06"
    )
    
    if st.button("ğŸ” RAG ile Analiz Et"):
        with st.spinner("RAG semantic search yapÄ±lÄ±yor..."):
            try:
                # RAG search test_final_rag.py'den
                sys.path.append('../Zgrprop')
                from test_final_rag import semantic_search
                
                # Metadata'dan query oluÅŸtur
                query = f"hotel lodging conference requirements {notice_id_rag}"
                
                relevant_chunks = semantic_search(query, limit=10)
                
                if relevant_chunks:
                    st.success(f"âœ… {len(relevant_chunks)} ilgili chunk bulundu")
                    
                    # Top chunks gÃ¶ster
                    for i, chunk in enumerate(relevant_chunks[:5], 1):
                        with st.expander(f"[{i}] {chunk['chunk_type'].upper()} - Similarity: {chunk['similarity']:.3f}"):
                            st.write(f"**Opportunity ID:** {chunk['opportunity_id']}")
                            st.write(f"**Content:**")
                            st.text(chunk['content'][:500])
                else:
                    st.warning("Ä°lgili chunk bulunamadÄ±")
            
            except Exception as e:
                st.error(f"RAG analizi hatasÄ±: {e}")
    
    # Teklif oluÅŸturma
    st.markdown("---")
    st.subheader("Teklif TaslaÄŸÄ± OluÅŸtur")
    
    if st.button("ğŸ“ Teklif TaslaÄŸÄ± OluÅŸtur"):
        st.info("Teklif oluÅŸturma Ã¶zelliÄŸi yakÄ±nda eklenecek...")
        # Burada teklif_raporu_olustur.py entegre edilebilir

if __name__ == "__main__":
    # Streamlit otomatik Ã§alÄ±ÅŸtÄ±rÄ±r
    pass

