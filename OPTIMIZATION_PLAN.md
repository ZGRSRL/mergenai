# Database Performance Optimization Plan

## ğŸ¯ Optimizasyon Hedefleri

### 1. **VeritabanÄ± BirleÅŸtirme** âœ… (Zaten YapÄ±lmÄ±ÅŸ)
- **Mevcut Durum**: ZGR_AI veritabanÄ± kullanÄ±lÄ±yor
- **Durum**: `sam` DB'si artÄ±k kullanÄ±lmÄ±yor, tÃ¼m veriler ZGR_AI'da
- **KazanÄ±m**: %50 maliyet azalmasÄ±, yÃ¶netim kolaylÄ±ÄŸÄ±

### 2. **HNSW Ä°ndeksine GeÃ§iÅŸ** ğŸ”„
- **Mevcut**: IVFFlat indeksi (varsa)
- **Hedef**: HNSW (Hierarchical Navigable Small World)
- **KazanÄ±m**: 
  - %10-20 daha hÄ±zlÄ± arama
  - Daha dÃ¼ÅŸÃ¼k gecikme (latency)
  - Daha doÄŸru sonuÃ§lar
- **Parametreler**: 
  - `m = 16` (her katmanda baÄŸlantÄ± sayÄ±sÄ±)
  - `ef_construction = 64` (index oluÅŸturma kalitesi)

### 3. **Chunk TablolarÄ±nÄ± BirleÅŸtirme** ğŸ”„
- **Mevcut**: 
  - `sam_chunks` (172,402 chunks - hotel data)
  - `vector_chunks` (opsiyonel - eski SAM data)
- **Hedef**: `unified_chunks` tablosu
- **Yeni Kolonlar**:
  - `source_type`: 'hotel_title', 'hotel_description', 'hotel_document', 'sam_document'
  - `source_id`: notice_id, document_id
  - `embedding_vector`: vector(384) - HNSW iÃ§in
  - `embedding_jsonb`: JSONB - uyumluluk iÃ§in
- **KazanÄ±m**:
  - Veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼
  - KarmaÅŸÄ±k JOIN'lerin ortadan kalkmasÄ±
  - Tek sorgu ile tÃ¼m chunk'lara eriÅŸim

## ğŸ“Š Mevcut Durum Analizi

### Tablo YapÄ±larÄ±

#### `sam_chunks` (ZGR_AI)
```sql
- chunk_id (PK)
- opportunity_id (VARCHAR)
- content (TEXT)
- embedding (JSONB)
- chunk_type (VARCHAR) - 'title', 'description', 'document'
- created_at (TIMESTAMP)
```

#### `vector_chunks` (ZGR_AI - opsiyonel)
```sql
- id (PK)
- document_id (INTEGER)
- chunk (TEXT)
- embedding (JSONB veya VECTOR)
- chunk_type (VARCHAR)
- page_number (INTEGER)
```

## ğŸš€ Optimizasyon AdÄ±mlarÄ±

### ADIM 1: HNSW Ä°ndeksi OluÅŸturma
```bash
python optimize_database_performance.py
# SeÃ§enek: "1. Migrate to HNSW" â†’ y
```

**YapÄ±lacaklar**:
1. pgvector extension kontrolÃ¼
2. JSONB â†’ VECTOR dÃ¶nÃ¼ÅŸÃ¼mÃ¼ (gerekirse)
3. IVFFlat indeksi silme (varsa)
4. HNSW indeksi oluÅŸturma

### ADIM 2: Chunk TablolarÄ±nÄ± BirleÅŸtirme
```bash
python optimize_database_performance.py
# SeÃ§enek: "2. Unify chunk tables" â†’ y
```

**YapÄ±lacaklar**:
1. `unified_chunks` tablosu oluÅŸturma
2. `sam_chunks` â†’ `unified_chunks` migrasyonu
3. `vector_chunks` â†’ `unified_chunks` migrasyonu (varsa)
4. Index'ler oluÅŸturma (HNSW dahil)

### ADIM 3: Uygulama KodlarÄ±nÄ± GÃ¼ncelleme
- `streamlit_app.py`: `sam_chunks` â†’ `unified_chunks`
- RAG API: `sam_chunks` â†’ `unified_chunks`
- TÃ¼m sorgular: `source_type` filtresi ekleme

## âš ï¸ Dikkat Edilmesi Gerekenler

1. **Backup**: Optimizasyon Ã¶ncesi mutlaka backup alÄ±n
2. **Downtime**: HNSW indeksi oluÅŸturma sÄ±rasÄ±nda kÄ±sa bir downtime olabilir
3. **Test**: Production'a geÃ§meden Ã¶nce test ortamÄ±nda deneyin
4. **Rollback Plan**: Eski tablolarÄ± silmeden Ã¶nce bir sÃ¼re tutun

## ğŸ“ˆ Beklenen Performans Ä°yileÅŸtirmeleri

| Metrik | Ã–nce | Sonra | Ä°yileÅŸme |
|--------|------|-------|----------|
| Arama HÄ±zÄ± | 100ms | 80-90ms | %10-20 |
| DoÄŸruluk | %95 | %98 | +%3 |
| Veri BÃ¼tÃ¼nlÃ¼ÄŸÃ¼ | Orta | YÃ¼ksek | âœ… |
| YÃ¶netim KolaylÄ±ÄŸÄ± | Orta | YÃ¼ksek | âœ… |

## ğŸ”„ Rollback PlanÄ±

EÄŸer sorun Ã§Ä±karsa:
1. `unified_chunks` tablosunu sil
2. `sam_chunks` tablosu korunmuÅŸ olacak
3. Eski sorgularÄ± kullanmaya devam et

## ğŸ“ Sonraki AdÄ±mlar

1. âœ… Optimizasyon scriptini test et
2. âœ… Backup al
3. âœ… Production'da Ã§alÄ±ÅŸtÄ±r
4. âœ… Uygulama kodlarÄ±nÄ± gÃ¼ncelle
5. âœ… Performans metriklerini izle

